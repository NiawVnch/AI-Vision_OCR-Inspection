import cv2
import pytesseract
import csv
import os
import re
import numpy as np
import socket
from collections import deque
import threading
import time  # Added for synchronization timing

# Set the mode
real_time_mode = True

# Specify the path to the image file (not used in real-time mode)
image_path = "GrayCO2.JPEG"

OCR = True

# Initialize the camera (only used in real-time mode)
if real_time_mode:
    cap = cv2.VideoCapture(5)
    fps = 25  # Desired frame rate (fps)
    cap.set(cv2.CAP_PROP_FPS, fps)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, int(640 * 0.85))
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, int(480 * 0.85))

# Define the expected OCR pattern
expected_pattern = r'A\d{10}'
detected_text_history = deque(maxlen=10)  # Keep track of previous OCR results

# TCP/IP server settings for PLC trigger
PLC_IP = "0.0.0.0"  # Listen on all interfaces
PLC_PORT = 5000      # The port to listen to PLC signals
plc_trigger_received = False  # Flag for when PLC sends a trigger

# Shared variables and locks for frames and processed results
latest_frame = None
frame_lock = threading.Lock()

latest_processed_frame = None
processed_frame_lock = threading.Lock()

# Shared variable for stable_text
stable_text_lock = threading.Lock()
stable_text = ""  # Initialized globally

# Shared variables and locks for mean_intensity and background_type
mean_intensity_lock = threading.Lock()
mean_intensity_value = 0
background_type_value = ''

# Lock for crop_coords
crop_coords_lock = threading.Lock()

# Variables for mouse drawing
drawing = False  # True if the mouse is pressed
ix, iy = -1, -1  # Initial x and y coordinates
temp_crop_coords = None  # Temporary crop coordinates during drawing

# Event to signal when OCR result is ready
ocr_result_ready = threading.Event()

# Function to handle PLC trigger and send OCR result
def plc_server():
    global plc_trigger_received, stable_text
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:
        server_socket.bind((PLC_IP, PLC_PORT))
        server_socket.listen()
        print(f"Listening for PLC trigger on {PLC_IP}:{PLC_PORT}...")
        while True:
            conn, addr = server_socket.accept()
            with conn:
                print(f"Connection from {addr}")
                try:
                    data = conn.recv(1024)
                    if data:
                        message = data.decode('utf-8').strip()
                        print(f"Received message from PLC: {message}")
                        if message == "TRIGGER":
                            print("PLC trigger received!")
                            plc_trigger_received = True

                            # Wait for OCR processing to complete and stable_text to be updated
                            ocr_result_ready.wait(timeout=5)  # Wait up to 5 seconds
                            ocr_result_ready.clear()  # Reset the event

                            # Lock and get the OCR result
                            with stable_text_lock:
                                result_to_send = stable_text
                                stable_text = ""  # Reset after sending

                            if result_to_send:
                                # Send OCR result back to PLC
                                conn.sendall(result_to_send.encode())
                                print(f"Sent OCR result to PLC: {result_to_send}")
                            else:
                                # Send an error message if OCR result is not available
                                conn.sendall(b'OCR failed or timeout')
                                print("No OCR result available to send to PLC.")
                        else:
                            print("Unknown message received from PLC.")
                            conn.sendall(b'Unknown command')
                    else:
                        print("No data received from PLC.")
                except Exception as e:
                    print(f"Error handling PLC connection: {e}")
            # Connection is closed automatically

# Function to save trackbar parameters
def save_parameters():
    block_size_light = cv2.getTrackbarPos('Block Size Light', 'OCR Combined Video')
    c_light = cv2.getTrackbarPos('C Light', 'OCR Combined Video')
    block_size_dark = cv2.getTrackbarPos('Block Size Dark', 'OCR Combined Video')
    c_dark = -cv2.getTrackbarPos('C Dark', 'OCR Combined Video')  # Stored as negative value
    blur_kernel_size = cv2.getTrackbarPos('Blur Kernel Size', 'OCR Combined Video')
    erosion_kernel_size = cv2.getTrackbarPos('Erosion Kernel Size', 'OCR Combined Video')
    dilation_kernel_size = cv2.getTrackbarPos('Dilation Kernel Size', 'OCR Combined Video')
    resize_scale = cv2.getTrackbarPos('Resize Scale (%)', 'OCR Combined Video')
    min_contour_area = cv2.getTrackbarPos('Min Contour Area', 'OCR Combined Video')

    with crop_coords_lock:
        current_crop_coords = str(crop_coords)

    with open('parameters.csv', mode='w', newline='') as file:
        fieldnames = ['Crop Coordinate', 'Block Size Light', 'C Light', 'Block Size Dark', 'C Dark',
                      'Blur Kernel Size', 'Erosion Kernel Size', 'Dilation Kernel Size', 'Resize Scale', 'Min Contour Area']
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerow({'Crop Coordinate': current_crop_coords,
                         'Block Size Light': block_size_light,
                         'C Light': c_light,
                         'Block Size Dark': block_size_dark,
                         'C Dark': c_dark,
                         'Blur Kernel Size': blur_kernel_size,
                         'Erosion Kernel Size': erosion_kernel_size,
                         'Dilation Kernel Size': dilation_kernel_size,
                         'Resize Scale': resize_scale,
                         'Min Contour Area': min_contour_area})

# Load parameters from CSV
def load_parameters():
    if os.path.exists('parameters.csv'):
        with open('parameters.csv', mode='r') as file:
            reader = csv.DictReader(file)
            params = next(reader)
            crop_coords = eval(params['Crop Coordinate'])
            block_size_light = int(params['Block Size Light'])
            c_light = int(params['C Light'])
            block_size_dark = int(params['Block Size Dark'])
            c_dark = int(params['C Dark'])  # Already negative
            blur_kernel_size = int(params['Blur Kernel Size'])
            erosion_kernel_size = int(params['Erosion Kernel Size'])
            dilation_kernel_size = int(params['Dilation Kernel Size'])
            resize_scale = int(params['Resize Scale'])
            min_contour_area = int(params.get('Min Contour Area', 100))
            return (crop_coords, block_size_light, c_light, block_size_dark, c_dark, blur_kernel_size,
                    erosion_kernel_size, dilation_kernel_size, resize_scale, min_contour_area)
    # Default values
    crop_coords = (100, 100, 720, 328)
    block_size_light = 11
    c_light = 2
    block_size_dark = 11
    c_dark = -2
    blur_kernel_size = 5
    erosion_kernel_size = 1
    dilation_kernel_size = 1
    resize_scale = 100
    min_contour_area = 100
    return (crop_coords, block_size_light, c_light, block_size_dark, c_dark, blur_kernel_size,
            erosion_kernel_size, dilation_kernel_size, resize_scale, min_contour_area)

# Load parameters
(crop_coords, block_size_light, c_light, block_size_dark, c_dark, blur_kernel_size,
 erosion_kernel_size, dilation_kernel_size, resize_scale, min_contour_area) = load_parameters()

# Update and save function for trackbars
def update_and_save(val):
    save_parameters()

# Mouse callback function for drawing the crop rectangle
def draw_crop_rectangle(event, x, y, flags, param):
    global ix, iy, drawing, temp_crop_coords, crop_coords
    if event == cv2.EVENT_LBUTTONDOWN:
        drawing = True
        ix, iy = x, y
        temp_crop_coords = (ix, iy, ix, iy)
    elif event == cv2.EVENT_MOUSEMOVE:
        if drawing:
            temp_crop_coords = (ix, iy, x, y)
    elif event == cv2.EVENT_LBUTTONUP:
        drawing = False
        temp_crop_coords = None
        with crop_coords_lock:
            crop_coords = (min(ix, x), min(iy, y), max(ix, x), max(iy, y))
        save_parameters()

# Create window and trackbars
cv2.namedWindow('OCR Combined Video')
cv2.createTrackbar('Block Size Light', 'OCR Combined Video', block_size_light, 255, update_and_save)
cv2.createTrackbar('C Light', 'OCR Combined Video', c_light, 100, update_and_save)
cv2.createTrackbar('Block Size Dark', 'OCR Combined Video', block_size_dark, 255, update_and_save)
cv2.createTrackbar('C Dark', 'OCR Combined Video', abs(c_dark), 100, update_and_save)
cv2.createTrackbar('Blur Kernel Size', 'OCR Combined Video', blur_kernel_size, 50, update_and_save)
cv2.createTrackbar('Erosion Kernel Size', 'OCR Combined Video', erosion_kernel_size, 20, update_and_save)
cv2.createTrackbar('Dilation Kernel Size', 'OCR Combined Video', dilation_kernel_size, 20, update_and_save)
cv2.createTrackbar('Resize Scale (%)', 'OCR Combined Video', resize_scale, 300, update_and_save)
cv2.createTrackbar('Min Contour Area', 'OCR Combined Video', min_contour_area, 1000, update_and_save)

# Set mouse callback
cv2.setMouseCallback('OCR Combined Video', draw_crop_rectangle)

# Noise removal
def remove_noise(image, kernel_size):
    if kernel_size % 2 == 0:
        kernel_size += 1
    if kernel_size < 1:
        kernel_size = 1
    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)

# Apply morphology
def apply_morphology(binary_image, erosion_size, dilation_size):
    if erosion_size < 1:
        erosion_size = 1
    if dilation_size < 1:
        dilation_size = 1
    erosion_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (erosion_size, erosion_size))
    dilation_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (dilation_size, dilation_size))
    eroded = cv2.erode(binary_image, erosion_kernel, iterations=1)
    dilated = cv2.dilate(eroded, dilation_kernel, iterations=1)
    return dilated

# Function to sharpen image
def sharpen_image(image):
    kernel = np.array([[0, -1, 0],
                       [-1, 5,-1],
                       [0, -1, 0]])
    return cv2.filter2D(src=image, ddepth=-1, kernel=kernel)

# Get the most frequent OCR result
def get_stabilized_text(history):
    if not history:
        return ""
    text_counts = {}
    for text in history:
        text_counts[text] = text_counts.get(text, 0) + 1
    return max(text_counts, key=text_counts.get)

# Function to detect background type
def detect_background_type(image):
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    mean_intensity = np.mean(gray_image)
    # Define thresholds based on your specific conditions
    if mean_intensity > 120:
        return mean_intensity, 'Light'
    else:
        return mean_intensity, 'Dark'

# OCR processing function
def perform_ocr():
    global detected_text_history, stable_text, latest_frame, latest_processed_frame
    global mean_intensity_value, background_type_value

    # Get the latest frame
    with frame_lock:
        if latest_frame is None:
            return False  # No frame available
        frame = latest_frame.copy()

    # Process frame for OCR
    with crop_coords_lock:
        x1, y1, x2, y2 = crop_coords
    cropped = frame[y1:y2, x1:x2]

    # Detect background type
    mean_intensity, background_type = detect_background_type(cropped)

    # Store mean_intensity and background_type in shared variables
    with mean_intensity_lock:
        mean_intensity_value = mean_intensity
        background_type_value = background_type

    # Get the appropriate parameters based on background type
    if background_type == 'Light':
        block_size = cv2.getTrackbarPos('Block Size Light', 'OCR Combined Video')
        c_value = cv2.getTrackbarPos('C Light', 'OCR Combined Video')
        threshold_type = cv2.THRESH_BINARY_INV
    else:  # 'Dark'
        block_size = cv2.getTrackbarPos('Block Size Dark', 'OCR Combined Video')
        c_value = -cv2.getTrackbarPos('C Dark', 'OCR Combined Video')
        threshold_type = cv2.THRESH_BINARY

    # Ensure block_size is odd and greater than or equal to 3
    if block_size % 2 == 0:
        block_size += 1
    if block_size < 3:
        block_size = 3

    # Resize the cropped image
    resize_scale = cv2.getTrackbarPos('Resize Scale (%)', 'OCR Combined Video')
    scale_factor = max(resize_scale / 100.0, 0.1)
    resized_cropped = cv2.resize(cropped, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)

    gray = cv2.cvtColor(resized_cropped, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(2, 2))
    equalized = clahe.apply(gray)
    denoised = remove_noise(equalized, cv2.getTrackbarPos('Blur Kernel Size', 'OCR Combined Video'))

    # Sharpen the image
    sharpened = sharpen_image(denoised)

    # Adaptive thresholding
    thresh = cv2.adaptiveThreshold(
        sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        threshold_type, block_size, c_value
    )

    erosion_kernel_size = cv2.getTrackbarPos('Erosion Kernel Size', 'OCR Combined Video')
    dilation_kernel_size = cv2.getTrackbarPos('Dilation Kernel Size', 'OCR Combined Video')
    morphed = apply_morphology(thresh, erosion_kernel_size, dilation_kernel_size)

    # Contour filtering to eliminate small noise
    min_contour_area = cv2.getTrackbarPos('Min Contour Area', 'OCR Combined Video')
    contours, hierarchy = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    mask = np.zeros_like(morphed)
    for contour in contours:
        area = cv2.contourArea(contour)
        if area >= min_contour_area:
            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)
    morphed = cv2.bitwise_and(morphed, mask)

    # Perform OCR
    custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
    ocr_result = pytesseract.image_to_string(morphed, config=custom_config)
    detected_text = ''.join(filter(str.isalnum, ocr_result))
    detected_text_history.append(detected_text)

    # Lock and update the stable text
    with stable_text_lock:
        stable_text = get_stabilized_text(detected_text_history)

    # Draw bounding boxes
    h, w = morphed.shape
    threshold_bgr = cv2.cvtColor(morphed, cv2.COLOR_GRAY2BGR)
    boxes = pytesseract.image_to_boxes(morphed, config=custom_config)
    for box in boxes.splitlines():
        box = box.split()
        if len(box) >= 5:
            x_b, y_b, x2_b, y2_b = int(box[1]), int(box[2]), int(box[3]), int(box[4])
            y_b = h - y_b
            y2_b = h - y2_b
            cv2.rectangle(threshold_bgr, (x_b, y2_b), (x2_b, y_b), (0, 255, 0), 2)

    # Resize back to original frame size for display
    resized_thresh = cv2.resize(threshold_bgr, (frame.shape[1], frame.shape[0]))

    # Save the processed frame
    with processed_frame_lock:
        latest_processed_frame = resized_thresh

    return True  # OCR processing completed

# Main loop
def main():
    global plc_trigger_received, stable_text, latest_frame, latest_processed_frame
    global mean_intensity_value, background_type_value

    # Start the PLC server thread
    plc_thread = threading.Thread(target=plc_server, daemon=True)
    plc_thread.start()

    try:
        if real_time_mode:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # Update the latest frame
                with frame_lock:
                    latest_frame = frame.copy()

                # Lock and display stable_text
                with stable_text_lock:
                    display_text = stable_text

                # Display information on the frame
                cv2.putText(frame, f"Detected: {display_text}", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(frame, f"Match: {'OK' if re.match(expected_pattern, display_text) else 'Not match'}",
                            (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                # Lock and get mean_intensity and background_type
                with mean_intensity_lock:
                    mean_intensity_display = mean_intensity_value
                    background_type_display = background_type_value

                # Display mean_intensity and background_type on the frame
                cv2.putText(frame, f"Mean Intensity: {mean_intensity_display:.2f}", (10, 90),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(frame, f"Background: {background_type_display}", (10, 120),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                # Draw the crop rectangle
                if drawing and temp_crop_coords is not None:
                    x1_t, y1_t, x2_t, y2_t = temp_crop_coords
                    cv2.rectangle(frame, (x1_t, y1_t), (x2_t, y2_t), (0, 0, 255), 1)
                else:
                    with crop_coords_lock:
                        x1, y1, x2, y2 = crop_coords
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)

                # Get the latest processed frame
                with processed_frame_lock:
                    if latest_processed_frame is not None:
                        last_processed_frame = latest_processed_frame.copy()
                    else:
                        last_processed_frame = None

                if last_processed_frame is not None:
                    combined = np.hstack((frame, last_processed_frame))
                else:
                    blank_image = np.zeros_like(frame)
                    combined = np.hstack((frame, blank_image))

                cv2.imshow('OCR Combined Video', combined)

                key = cv2.waitKey(1) & 0xFF
                if key == ord('c'):
                    print(f"OCR Capture: {display_text}")
                    # Manually trigger OCR processing
                    if perform_ocr():
                        ocr_result_ready.set()  # Signal that OCR result is ready
                if key == ord('q'):
                    break

                if plc_trigger_received:
                    # Perform OCR processing upon PLC trigger
                    if perform_ocr():
                        ocr_result_ready.set()  # Signal that OCR result is ready
                    else:
                        print("Failed to perform OCR.")
                    plc_trigger_received = False

    finally:
        if real_time_mode and cap.isOpened():
            cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
