import cv2
import pytesseract
import csv
import os
import re
import numpy as np
import threading
import time
from collections import deque
from pymodbus.client.sync import ModbusTcpClient
from pymodbus.constants import Endian
from pymodbus.payload import BinaryPayloadBuilder

# Set the mode
real_time_mode = True

# Initialize the camera (only used in real-time mode)
if real_time_mode:
    cap = cv2.VideoCapture(5)
    fps = 25  # Desired frame rate (fps)
    cap.set(cv2.CAP_PROP_FPS, fps)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, int(640 * 0.85))
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, int(480 * 0.85))

# Define the expected OCR pattern
expected_pattern = r'A\d{10}'
detected_text_history = deque(maxlen=5)  # Keep track of previous OCR results

# PLC settings
PLC_IP = '192.168.1.5'  # Replace with your PLC's IP address
PLC_PORT = 502  # Modbus TCP default port
PLC_TRIGGER_COIL = 0  # Coil address for trigger (adjust as needed)
PLC_RESULT_REGISTER = 100  # Starting register address for OCR result (adjust as needed)
PLC_RESULT_REGISTERS_COUNT = 20  # Number of registers to hold the OCR result

# Shared variables and locks for frames and processed results
latest_frame = None
frame_lock = threading.Lock()

latest_processed_frame = None
processed_frame_lock = threading.Lock()

# Shared variable for stable_text
stable_text_lock = threading.Lock()
stable_text = ""  # Initialized globally

# Shared variables and locks for mean_intensity and background_type
mean_intensity_lock = threading.Lock()
mean_intensity_value = 0
background_type_value = ''

# Lock for crop_coords
crop_coords_lock = threading.Lock()

# Variables for mouse drawing
drawing = False  # True if the mouse is pressed
ix, iy = -1, -1  # Initial x and y coordinates
temp_crop_coords = None  # Temporary crop coordinates during drawing

# Function to handle PLC communication via Modbus TCP
def plc_communication():
    global stable_text
    try:
        client = ModbusTcpClient(PLC_IP, port=PLC_PORT)
        if not client.connect():
            print(f"Failed to connect to PLC at {PLC_IP}:{PLC_PORT}")
            return
        print(f"Connected to PLC at {PLC_IP}:{PLC_PORT}")

        while True:
            try:
                # Read the trigger coil from the PLC
                response = client.read_coils(PLC_TRIGGER_COIL, 1)
                if response.isError():
                    print(f"Error reading trigger coil: {response}")
                    time.sleep(1)
                    continue

                trigger = response.bits[0]
                if trigger:
                    print("PLC trigger received!")
                    # Get the latest stable_text
                    with stable_text_lock:
                        ocr_result = stable_text

                    if ocr_result:
                        # Encode the OCR result into registers
                        builder = BinaryPayloadBuilder(byteorder=Endian.Big, wordorder=Endian.Big)
                        # Pad or truncate the string to fit into the registers
                        max_chars = PLC_RESULT_REGISTERS_COUNT * 2  # 2 chars per register (assuming ASCII)
                        ocr_result_padded = ocr_result.ljust(max_chars)[:max_chars]
                        builder.add_string(ocr_result_padded.encode('ascii'))

                        payload = builder.to_registers()
                        # Write the OCR result to the PLC
                        write_response = client.write_registers(PLC_RESULT_REGISTER, payload)
                        if write_response.isError():
                            print(f"Error writing OCR result to PLC: {write_response}")
                        else:
                            print(f"Sent OCR result to PLC: {ocr_result_padded}")
                    else:
                        print("No OCR result available to send")

                    # Reset the trigger coil in the PLC
                    reset_response = client.write_coil(PLC_TRIGGER_COIL, False)
                    if reset_response.isError():
                        print(f"Error resetting trigger coil: {reset_response}")
                time.sleep(0.1)
            except Exception as e:
                print(f"PLC communication error inside loop: {e}")
                time.sleep(5)
    except Exception as e:
        print(f"PLC communication error: {e}")
    finally:
        client.close()
        print("PLC client connection closed")

# Function to save trackbar parameters
def save_parameters():
    try:
        block_size_light = cv2.getTrackbarPos('Block Size Light', 'OCR Combined Video')
        c_light = cv2.getTrackbarPos('C Light', 'OCR Combined Video')
        block_size_dark = cv2.getTrackbarPos('Block Size Dark', 'OCR Combined Video')
        c_dark = -cv2.getTrackbarPos('C Dark', 'OCR Combined Video')  # Stored as negative value
        blur_kernel_size = cv2.getTrackbarPos('Blur Kernel Size', 'OCR Combined Video')
        erosion_kernel_size = cv2.getTrackbarPos('Erosion Kernel Size', 'OCR Combined Video')
        dilation_kernel_size = cv2.getTrackbarPos('Dilation Kernel Size', 'OCR Combined Video')
        resize_scale = cv2.getTrackbarPos('Resize Scale (%)', 'OCR Combined Video')
        min_contour_area = cv2.getTrackbarPos('Min Contour Area', 'OCR Combined Video')  # New parameter

        with crop_coords_lock:
            current_crop_coords = str(crop_coords)

        with open('parameters.csv', mode='w', newline='') as file:
            fieldnames = ['Crop Coordinate', 'Block Size Light', 'C Light', 'Block Size Dark', 'C Dark',
                          'Blur Kernel Size', 'Erosion Kernel Size', 'Dilation Kernel Size', 'Resize Scale', 'Min Contour Area']
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerow({'Crop Coordinate': current_crop_coords,
                             'Block Size Light': block_size_light,
                             'C Light': c_light,
                             'Block Size Dark': block_size_dark,
                             'C Dark': c_dark,
                             'Blur Kernel Size': blur_kernel_size,
                             'Erosion Kernel Size': erosion_kernel_size,
                             'Dilation Kernel Size': dilation_kernel_size,
                             'Resize Scale': resize_scale,
                             'Min Contour Area': min_contour_area})  # Save new parameter
    except Exception as e:
        print(f"Error saving parameters: {e}")

# Load parameters from CSV
def load_parameters():
    try:
        if os.path.exists('parameters.csv'):
            with open('parameters.csv', mode='r') as file:
                reader = csv.DictReader(file)
                params = next(reader)
                crop_coords = eval(params['Crop Coordinate'])
                block_size_light = int(params['Block Size Light'])
                c_light = int(params['C Light'])
                block_size_dark = int(params['Block Size Dark'])
                c_dark = int(params['C Dark'])  # Already negative
                blur_kernel_size = int(params['Blur Kernel Size'])
                erosion_kernel_size = int(params['Erosion Kernel Size'])
                dilation_kernel_size = int(params['Dilation Kernel Size'])
                resize_scale = int(params['Resize Scale'])
                min_contour_area = int(params.get('Min Contour Area', 100))  # Load new parameter with default
                return (crop_coords, block_size_light, c_light, block_size_dark, c_dark, blur_kernel_size,
                        erosion_kernel_size, dilation_kernel_size, resize_scale, min_contour_area)
        # Default values
        crop_coords = (100, 100, 720, 328)
        block_size_light = 11
        c_light = 2
        block_size_dark = 11
        c_dark = -2
        blur_kernel_size = 5
        erosion_kernel_size = 1
        dilation_kernel_size = 1
        resize_scale = 100
        min_contour_area = 100  # Default value for new parameter
        return (crop_coords, block_size_light, c_light, block_size_dark, c_dark, blur_kernel_size,
                erosion_kernel_size, dilation_kernel_size, resize_scale, min_contour_area)
    except Exception as e:
        print(f"Error loading parameters: {e}")
        # Return default values if there's an error
        crop_coords = (100, 100, 720, 328)
        block_size_light = 11
        c_light = 2
        block_size_dark = 11
        c_dark = -2
        blur_kernel_size = 5
        erosion_kernel_size = 1
        dilation_kernel_size = 1
        resize_scale = 100
        min_contour_area = 100
        return (crop_coords, block_size_light, c_light, block_size_dark, c_dark, blur_kernel_size,
                erosion_kernel_size, dilation_kernel_size, resize_scale, min_contour_area)

# Load parameters
(crop_coords, block_size_light, c_light, block_size_dark, c_dark, blur_kernel_size,
 erosion_kernel_size, dilation_kernel_size, resize_scale, min_contour_area) = load_parameters()

# Update and save function for trackbars
def update_and_save(val):
    save_parameters()

# Mouse callback function for drawing the crop rectangle
def draw_crop_rectangle(event, x, y, flags, param):
    global ix, iy, drawing, temp_crop_coords, crop_coords
    try:
        if event == cv2.EVENT_LBUTTONDOWN:
            drawing = True
            ix, iy = x, y
            temp_crop_coords = (ix, iy, ix, iy)
        elif event == cv2.EVENT_MOUSEMOVE:
            if drawing:
                temp_crop_coords = (ix, iy, x, y)
        elif event == cv2.EVENT_LBUTTONUP:
            drawing = False
            temp_crop_coords = None
            with crop_coords_lock:
                crop_coords = (min(ix, x), min(iy, y), max(ix, x), max(iy, y))
            save_parameters()
    except Exception as e:
        print(f"Error in draw_crop_rectangle: {e}")

# Create window and trackbars
try:
    cv2.namedWindow('OCR Combined Video')
    cv2.createTrackbar('Block Size Light', 'OCR Combined Video', block_size_light, 255, update_and_save)
    cv2.createTrackbar('C Light', 'OCR Combined Video', c_light, 100, update_and_save)
    cv2.createTrackbar('Block Size Dark', 'OCR Combined Video', block_size_dark, 255, update_and_save)
    cv2.createTrackbar('C Dark', 'OCR Combined Video', abs(c_dark), 100, update_and_save)
    cv2.createTrackbar('Blur Kernel Size', 'OCR Combined Video', blur_kernel_size, 50, update_and_save)
    cv2.createTrackbar('Erosion Kernel Size', 'OCR Combined Video', erosion_kernel_size, 20, update_and_save)
    cv2.createTrackbar('Dilation Kernel Size', 'OCR Combined Video', dilation_kernel_size, 20, update_and_save)
    cv2.createTrackbar('Resize Scale (%)', 'OCR Combined Video', resize_scale, 300, update_and_save)
    cv2.createTrackbar('Min Contour Area', 'OCR Combined Video', min_contour_area, 1000, update_and_save)  # New trackbar

    # Set mouse callback
    cv2.setMouseCallback('OCR Combined Video', draw_crop_rectangle)
except Exception as e:
    print(f"Error creating window or trackbars: {e}")

# Noise removal
def remove_noise(image, kernel_size):
    try:
        if kernel_size % 2 == 0:
            kernel_size += 1
        if kernel_size < 1:
            kernel_size = 1
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    except Exception as e:
        print(f"Error in remove_noise: {e}")
        return image

# Apply morphology
def apply_morphology(binary_image, erosion_size, dilation_size):
    try:
        if erosion_size < 1:
            erosion_size = 1
        if dilation_size < 1:
            dilation_size = 1
        erosion_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (erosion_size, erosion_size))
        dilation_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (dilation_size, dilation_size))
        eroded = cv2.erode(binary_image, erosion_kernel, iterations=1)
        dilated = cv2.dilate(eroded, dilation_kernel, iterations=1)
        return dilated
    except Exception as e:
        print(f"Error in apply_morphology: {e}")
        return binary_image

# Function to sharpen image
def sharpen_image(image):
    try:
        kernel = np.array([[0, -1, 0],
                           [-1, 5,-1],
                           [0, -1, 0]])
        return cv2.filter2D(src=image, ddepth=-1, kernel=kernel)
    except Exception as e:
        print(f"Error in sharpen_image: {e}")
        return image

# Get the most frequent OCR result
def get_stabilized_text(history):
    try:
        if not history:
            return ""
        text_counts = {}
        for text in history:
            text_counts[text] = text_counts.get(text, 0) + 1
        return max(text_counts, key=text_counts.get)
    except Exception as e:
        print(f"Error in get_stabilized_text: {e}")
        return ""

# Function to detect background type
def detect_background_type(image):
    try:
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        mean_intensity = np.mean(gray_image)
        # Define thresholds based on your specific conditions
        if mean_intensity > 120:
            return mean_intensity, 'Light'
        else:
            return mean_intensity, 'Dark'
    except Exception as e:
        print(f"Error in detect_background_type: {e}")
        return 0, 'Unknown'

# OCR processing in a separate thread
def process_ocr():
    global detected_text_history, stable_text, latest_frame, latest_processed_frame
    global mean_intensity_value, background_type_value
    try:
        while True:
            try:
                # Get the latest frame
                with frame_lock:
                    if latest_frame is None:
                        continue
                    frame = latest_frame.copy()

                # Process frame for OCR
                with crop_coords_lock:
                    x1, y1, x2, y2 = crop_coords
                cropped = frame[y1:y2, x1:x2]

                # Detect background type
                mean_intensity, background_type = detect_background_type(cropped)

                # Store mean_intensity and background_type in shared variables
                with mean_intensity_lock:
                    mean_intensity_value = mean_intensity
                    background_type_value = background_type

                # Get the appropriate parameters based on background type
                if background_type == 'Light':
                    block_size = cv2.getTrackbarPos('Block Size Light', 'OCR Combined Video')
                    c_value = cv2.getTrackbarPos('C Light', 'OCR Combined Video')
                    threshold_type = cv2.THRESH_BINARY_INV
                elif background_type == 'Dark':
                    block_size = cv2.getTrackbarPos('Block Size Dark', 'OCR Combined Video')
                    c_value = -cv2.getTrackbarPos('C Dark', 'OCR Combined Video')
                    threshold_type = cv2.THRESH_BINARY
                else:
                    block_size = 11
                    c_value = 2
                    threshold_type = cv2.THRESH_BINARY

                # Ensure block_size is odd and greater than or equal to 3
                if block_size % 2 == 0:
                    block_size += 1
                if block_size < 3:
                    block_size = 3

                # Resize the cropped image
                resize_scale = cv2.getTrackbarPos('Resize Scale (%)', 'OCR Combined Video')
                scale_factor = max(resize_scale / 100.0, 0.1)
                resized_cropped = cv2.resize(cropped, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)

                gray = cv2.cvtColor(resized_cropped, cv2.COLOR_BGR2GRAY)
                clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(2, 2))
                equalized = clahe.apply(gray)
                denoised = remove_noise(equalized, cv2.getTrackbarPos('Blur Kernel Size', 'OCR Combined Video'))

                # Sharpen the image
                sharpened = sharpen_image(denoised)

                # Adaptive thresholding
                thresh = cv2.adaptiveThreshold(
                    sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                    threshold_type, block_size, c_value
                )

                erosion_kernel_size = cv2.getTrackbarPos('Erosion Kernel Size', 'OCR Combined Video')
                dilation_kernel_size = cv2.getTrackbarPos('Dilation Kernel Size', 'OCR Combined Video')
                morphed = apply_morphology(thresh, erosion_kernel_size, dilation_kernel_size)

                # Contour filtering to eliminate small noise
                min_contour_area = cv2.getTrackbarPos('Min Contour Area', 'OCR Combined Video')
                contours, hierarchy = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                mask = np.zeros_like(morphed)
                for contour in contours:
                    area = cv2.contourArea(contour)
                    if area >= min_contour_area:
                        cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)
                morphed = cv2.bitwise_and(morphed, mask)

                # Perform OCR
                custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789A'
                ocr_result = pytesseract.image_to_string(morphed, config=custom_config)
                detected_text = ''.join(filter(str.isalnum, ocr_result))
                detected_text_history.append(detected_text)

                # Lock and update the stable text
                with stable_text_lock:
                    stable_text = get_stabilized_text(detected_text_history)

                # Draw bounding boxes
                h, w = morphed.shape
                threshold_bgr = cv2.cvtColor(morphed, cv2.COLOR_GRAY2BGR)
                boxes = pytesseract.image_to_boxes(morphed, config=custom_config)
                for box in boxes.splitlines():
                    box = box.split()
                    if len(box) >= 5:
                        x_b, y_b, x2_b, y2_b = int(box[1]), int(box[2]), int(box[3]), int(box[4])
                        y_b = h - y_b
                        y2_b = h - y2_b
                        cv2.rectangle(threshold_bgr, (x_b, y2_b), (x2_b, y_b), (0, 255, 0), 2)

                # Resize back to original frame size for display
                resized_thresh = cv2.resize(threshold_bgr, (frame.shape[1], frame.shape[0]))

                # Save the processed frame
                with processed_frame_lock:
                    latest_processed_frame = resized_thresh
            except Exception as e:
                print(f"OCR processing error: {e}")
                time.sleep(0.1)
    except Exception as e:
        print(f"OCR thread error: {e}")

# Main loop
def main():
    global stable_text, latest_frame, latest_processed_frame
    global mean_intensity_value, background_type_value

    try:
        plc_thread = threading.Thread(target=plc_communication, daemon=True)
        plc_thread.start()

        ocr_thread = threading.Thread(target=process_ocr, daemon=True)
        ocr_thread.start()

        if real_time_mode:
            while True:
                try:
                    ret, frame = cap.read()
                    if not ret:
                        print("Failed to read frame from camera")
                        break

                    # Update the latest frame
                    with frame_lock:
                        latest_frame = frame.copy()

                    # Lock and display stable_text
                    with stable_text_lock:
                        cv2.putText(frame, f"Detected: {stable_text}", (10, 30),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                        match_text = 'OK' if re.match(expected_pattern, stable_text) else 'Not match'
                        cv2.putText(frame, f"Match: {match_text}",
                                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                    # Lock and get mean_intensity and background_type
                    with mean_intensity_lock:
                        mean_intensity_display = mean_intensity_value
                        background_type_display = background_type_value

                    # Display mean_intensity and background_type on the frame
                    cv2.putText(frame, f"Mean Intensity: {mean_intensity_display:.2f}", (10, 90),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(frame, f"Background: {background_type_display}", (10, 120),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                    # Draw the crop rectangle
                    if drawing and temp_crop_coords is not None:
                        x1_t, y1_t, x2_t, y2_t = temp_crop_coords
                        cv2.rectangle(frame, (x1_t, y1_t), (x2_t, y2_t), (0, 0, 255), 1)
                    else:
                        with crop_coords_lock:
                            x1, y1, x2, y2 = crop_coords
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)

                    # Get the latest processed frame
                    with processed_frame_lock:
                        if latest_processed_frame is not None:
                            last_processed_frame = latest_processed_frame.copy()
                        else:
                            last_processed_frame = None

                    if last_processed_frame is not None:
                        combined = np.hstack((frame, last_processed_frame))
                    else:
                        blank_image = np.zeros_like(frame)
                        combined = np.hstack((frame, blank_image))

                    cv2.imshow('OCR Combined Video', combined)

                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('c'):
                        print(f"OCR Capture: {stable_text}")

                    if key == ord('q'):
                        break
                except Exception as e:
                    print(f"Error in main loop: {e}")
                    break
    except Exception as e:
        print(f"Main function error: {e}")
    finally:
        if real_time_mode and cap.isOpened():
            cap.release()
        cv2.destroyAllWindows()
        print("Program terminated gracefully")

if __name__ == "__main__":
    main()

/home/linaro/.pyenv/versions/3.11.9/bin/python "/home/linaro/Downloads/AI-Vision_OCR-Inspection-main/Adaptive Adjustmen for Marker inspection with OCR_rev11 (All BG Modbus TCP).py"
linaro@linaro-alip:~/Downloads/AI-Vision_OCR-Inspection-main$ /home/linaro/.pyenv/versions/3.11.9/bin/python "/home/linaro/Downloads/AI-Vision_OCR-Inspection-main/Adaptive Adjustmen for Marker inspection with OCR_rev11 (All BG Modbus TCP).py"
Connected to PLC at 192.168.1.5:888
Error reading trigger coil: Modbus Error: [Input/Output] Modbus Error: [Invalid Message] No response received, expected at least 8 bytes (0 received)
Error reading trigger coil: Modbus Error: [Input/Output] No Response received from the remote unit/Unable to decode response
Error reading trigger coil: Modbus Error: [Input/Output] No Response received from the remote unit/Unable to decode response
Error reading trigger coil: Modbus Error: [Input/Output] No Response received from the remote unit/Unable to decode response
Error reading trigger coil: Modbus Error: [Input/Output] No Response received from the remote unit/Unable to decode response
