import cv2
import pytesseract
import csv
import os
import re
import numpy as np
import socket
from collections import deque
import threading

# Set the mode
real_time_mode = True

# Specify the path to the image file
image_path = "GrayCO2.JPEG"

OCR = True

# Initialize the camera (only used in real-time mode)
if real_time_mode:
    cap = cv2.VideoCapture(5)
    fps = 25  # Desired frame rate (fps)
    cap.set(cv2.CAP_PROP_FPS, fps)

# Define the expected OCR pattern
expected_pattern = r'A\d{10}'
detected_text_history = deque(maxlen=10)  # Keep track of previous OCR results

# TCP/IP server settings for PLC trigger
PLC_IP = "0.0.0.0"  # The server IP address (0.0.0.0 listens to all interfaces)
PLC_PORT = 5000      # The port to listen to PLC signals
plc_trigger_received = False  # Flag for when PLC sends a trigger

# Shared variables and locks for frames and processed results
latest_frame = None
frame_lock = threading.Lock()

latest_processed_frame = None
processed_frame_lock = threading.Lock()

# Shared variable for stable_text
stable_text_lock = threading.Lock()
stable_text = ""  # Initialized globally

# Function to handle PLC trigger
def plc_server():
    global plc_trigger_received
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as server_socket:
        server_socket.bind((PLC_IP, PLC_PORT))
        server_socket.listen(1)
        print(f"Listening for PLC trigger on {PLC_IP}:{PLC_PORT}...")
        while True:
            conn, addr = server_socket.accept()
            with conn:
                print(f"Connection from {addr}")
                data = conn.recv(1024)
                if data:
                    print("PLC trigger received!")
                    plc_trigger_received = True
                    conn.sendall(b'Trigger received')

# Function to save trackbar parameters
def save_parameters():
    block_size = cv2.getTrackbarPos('Block Size', 'OCR Combined Video')
    c = cv2.getTrackbarPos('C', 'OCR Combined Video')
    blur_kernel_size = cv2.getTrackbarPos('Blur Kernel Size', 'OCR Combined Video')
    erosion_kernel_size = cv2.getTrackbarPos('Erosion Kernel Size', 'OCR Combined Video')
    dilation_kernel_size = cv2.getTrackbarPos('Dilation Kernel Size', 'OCR Combined Video')
    threshold_type = cv2.getTrackbarPos('Threshold Type', 'OCR Combined Video')
    resize_scale = cv2.getTrackbarPos('Resize Scale (%)', 'OCR Combined Video')

    with open('parameters.csv', mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['Crop Coordinate', 'Block Size', 'C', 'Blur Kernel Size',
                         'Erosion Kernel Size', 'Dilation Kernel Size', 'Threshold Type', 'Resize Scale'])
        writer.writerow([str(crop_coords), block_size, c, blur_kernel_size,
                         erosion_kernel_size, dilation_kernel_size, threshold_type, resize_scale])

# Load parameters from CSV
def load_parameters():
    if os.path.exists('parameters.csv'):
        with open('parameters.csv', mode='r') as file:
            reader = csv.reader(file)
            next(reader)
            params = next(reader)
            crop_coords = eval(params[0])
            return (crop_coords, int(params[1]), int(params[2]), int(params[3]), int(params[4]),
                    int(params[5]), int(params[6]), int(params[7]))
    # Default crop coordinates and parameters
    crop_coords = (100, 100, 720, 328)  # Adjusted to 620x228 pixels
    return crop_coords, 11, 2, 5, 1, 1, 0, 100

# Load parameters
(crop_coords, block_size, c, blur_kernel_size, erosion_kernel_size,
 dilation_kernel_size, threshold_type, resize_scale) = load_parameters()

# Update and save function for trackbars
def update_and_save(val):
    save_parameters()

# Create window and trackbars
cv2.namedWindow('OCR Combined Video')
cv2.createTrackbar('Block Size', 'OCR Combined Video', block_size, 255, update_and_save)
cv2.createTrackbar('C', 'OCR Combined Video', c, 100, update_and_save)
cv2.createTrackbar('Blur Kernel Size', 'OCR Combined Video', blur_kernel_size, 50, update_and_save)
cv2.createTrackbar('Erosion Kernel Size', 'OCR Combined Video', erosion_kernel_size, 20, update_and_save)
cv2.createTrackbar('Dilation Kernel Size', 'OCR Combined Video', dilation_kernel_size, 20, update_and_save)
cv2.createTrackbar('Threshold Type', 'OCR Combined Video', threshold_type, 1, update_and_save)
cv2.createTrackbar('Resize Scale (%)', 'OCR Combined Video', resize_scale, 300, update_and_save)

# Noise removal
def remove_noise(image, kernel_size):
    if kernel_size % 2 == 0:
        kernel_size += 1
    if kernel_size < 1:
        kernel_size = 1
    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)

# Apply morphology
def apply_morphology(binary_image, erosion_size, dilation_size):
    if erosion_size < 1:
        erosion_size = 1
    if dilation_size < 1:
        dilation_size = 1
    erosion_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (erosion_size, erosion_size))
    dilation_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (dilation_size, dilation_size))
    eroded = cv2.erode(binary_image, erosion_kernel, iterations=1)
    dilated = cv2.dilate(eroded, dilation_kernel, iterations=1)
    return dilated

# Function to sharpen image
def sharpen_image(image):
    kernel = np.array([[0, -1, 0],
                       [-1, 5,-1],
                       [0, -1, 0]])
    return cv2.filter2D(src=image, ddepth=-1, kernel=kernel)

# Function to send OCR result to server
def send_ocr_result(result):
    server_ip = "192.168.0.5"
    server_port = 12345
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(5)
            s.connect((server_ip, server_port))
            s.sendall(result.encode())
            print(f"Sent OCR result to server: {result}")
    except (socket.timeout, socket.error) as e:
        print(f"Error: Could not send OCR result to server. {e}")

# Get the most frequent OCR result
def get_stabilized_text(history):
    if not history:
        return ""
    text_counts = {}
    for text in history:
        text_counts[text] = text_counts.get(text, 0) + 1
    return max(text_counts, key=text_counts.get)

# OCR processing in a separate thread
def process_ocr():
    global detected_text_history, stable_text, latest_frame, latest_processed_frame
    while True:
        # Get the latest frame
        with frame_lock:
            if latest_frame is None:
                continue
            frame = latest_frame.copy()

        # Process frame for OCR
        x1, y1, x2, y2 = crop_coords
        cropped = frame[y1:y2, x1:x2]

        # Resize the cropped image
        resize_scale = cv2.getTrackbarPos('Resize Scale (%)', 'OCR Combined Video')
        scale_factor = max(resize_scale / 100.0, 0.1)
        resized_cropped = cv2.resize(cropped, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_LINEAR)

        gray = cv2.cvtColor(resized_cropped, cv2.COLOR_BGR2GRAY)
        clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(2, 2))
        equalized = clahe.apply(gray)
        denoised = remove_noise(equalized, cv2.getTrackbarPos('Blur Kernel Size', 'OCR Combined Video'))

        # Sharpen the image
        sharpened = sharpen_image(denoised)

        threshold_method = cv2.THRESH_BINARY if cv2.getTrackbarPos('Threshold Type', 'OCR Combined Video') == 0 else cv2.THRESH_BINARY_INV
        block_size = cv2.getTrackbarPos('Block Size', 'OCR Combined Video')
        c = cv2.getTrackbarPos('C', 'OCR Combined Video')

        if block_size % 2 == 0:
            block_size += 1
        if block_size < 3:
            block_size = 3

        thresh = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, threshold_method, block_size, c)
        erosion_kernel_size = cv2.getTrackbarPos('Erosion Kernel Size', 'OCR Combined Video')
        dilation_kernel_size = cv2.getTrackbarPos('Dilation Kernel Size', 'OCR Combined Video')
        morphed = apply_morphology(thresh, erosion_kernel_size, dilation_kernel_size)

        # Perform OCR
        custom_config = r'--oem 3 --psm 7 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'
        ocr_result = pytesseract.image_to_string(morphed, config=custom_config)
        detected_text = ''.join(filter(str.isalnum, ocr_result))
        detected_text_history.append(detected_text)

        # Lock and update the stable text
        with stable_text_lock:
            stable_text = get_stabilized_text(detected_text_history)

        # Draw bounding boxes
        h, w = morphed.shape
        threshold_bgr = cv2.cvtColor(morphed, cv2.COLOR_GRAY2BGR)
        boxes = pytesseract.image_to_boxes(morphed, config=custom_config)
        for box in boxes.splitlines():
            box = box.split()
            if len(box) >= 5:
                x, y, x2, y2 = int(box[1]), int(box[2]), int(box[3]), int(box[4])
                y = h - y
                y2 = h - y2
                cv2.rectangle(threshold_bgr, (x, y2), (x2, y), (0, 255, 0), 2)

        # Resize back to original frame size for display
        resized_thresh = cv2.resize(threshold_bgr, (frame.shape[1], frame.shape[0]))

        # Save the processed frame
        with processed_frame_lock:
            latest_processed_frame = resized_thresh

# Main loop
def main():
    global plc_trigger_received, stable_text, latest_frame, latest_processed_frame

    plc_thread = threading.Thread(target=plc_server, daemon=True)
    plc_thread.start()

    ocr_thread = threading.Thread(target=process_ocr, daemon=True)
    ocr_thread.start()

    try:
        if real_time_mode:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                x1, y1, x2, y2 = crop_coords
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 1)

                # Update the latest frame
                with frame_lock:
                    latest_frame = frame.copy()

                # Lock and display stable_text
                with stable_text_lock:
                    cv2.putText(frame, f"Detected: {stable_text}", (10, 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    cv2.putText(frame, f"Match: {'OK' if re.match(expected_pattern, stable_text) else 'Not match'}",
                                (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

                # Get the latest processed frame
                with processed_frame_lock:
                    if latest_processed_frame is not None:
                        last_processed_frame = latest_processed_frame.copy()
                    else:
                        last_processed_frame = None

                if last_processed_frame is not None:
                    combined = np.hstack((frame, last_processed_frame))
                else:
                    blank_image = np.zeros_like(frame)
                    combined = np.hstack((frame, blank_image))

                cv2.imshow('OCR Combined Video', combined)

                if cv2.waitKey(1) & 0xFF == ord('c'):
                    print(f"OCR Capture: {stable_text}")
                    if stable_text:
                        send_ocr_result(stable_text)

                if plc_trigger_received:
                    print(f"PLC-triggered OCR Capture: {stable_text}")
                    if stable_text:
                        send_ocr_result(stable_text)
                    plc_trigger_received = False

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
    finally:
        if real_time_mode and cap.isOpened():
            cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
